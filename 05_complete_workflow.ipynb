{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP0MLIUegdHAnz1+rTsZJXA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TranQuocHuy83/mlops_training---module02---HuyTran-/blob/main/05_complete_workflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6y3o30YoZyHO"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Exercise 5: Complete PyTorch Workflow\n",
        "PyTorch Workflow Fundamentals - Module 2\n",
        "\n",
        "This exercise covers:\n",
        "- Putting together the complete workflow\n",
        "- Device-agnostic code\n",
        "- Hyperparameter experimentation\n",
        "- Training from scratch to deployment\n",
        "- Comparing experiments\n",
        "\n",
        "Learning Mottos:\n",
        "- If in doubt, run the code!\n",
        "- Experiment, experiment, experiment!\n",
        "- Visualize, visualize, visualize!\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# ============================================\n",
        "# Part 1: Complete Workflow Function\n",
        "# ============================================\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"Part 1: Complete Workflow Function\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "\n",
        "def train_linear_regression(\n",
        "    weight=0.7,\n",
        "    bias=0.3,\n",
        "    train_ratio=0.7,\n",
        "    val_ratio=0.15,\n",
        "    learning_rate=0.01,\n",
        "    epochs=100,\n",
        "    device='cpu',\n",
        "    save_model=False,\n",
        "    model_name='linear_model'\n",
        "):\n",
        "    \"\"\"\n",
        "    Complete workflow for linear regression\n",
        "    \"\"\"\n",
        "    print(f\"\\nTraining with lr={learning_rate}, epochs={epochs}\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    # 1. Prepare data\n",
        "    X = torch.arange(0, 1, 0.02).unsqueeze(dim=1).to(device)\n",
        "    y = weight * X + bias\n",
        "\n",
        "    train_split = int(train_ratio * len(X))\n",
        "    val_split = int((train_ratio + val_ratio) * len(X))\n",
        "\n",
        "    X_train, y_train = X[:train_split], y[:train_split]\n",
        "    X_val, y_val = X[train_split:val_split], y[train_split:val_split]\n",
        "    X_test, y_test = X[val_split:], y[val_split:]\n",
        "\n",
        "    # 2. Build model\n",
        "\n",
        "\n",
        "    class LinearRegressionModel(nn.Module):\n",
        "        def __init__(self):\n",
        "            super().__init__()\n",
        "            self.weight = nn.Parameter(torch.randn(1))\n",
        "            self.bias = nn.Parameter(torch.randn(1))\n",
        "\n",
        "        def forward(self, x):\n",
        "            return self.weight * x + self.bias\n",
        "\n",
        "    model = LinearRegressionModel().to(device)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # 3. Train\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        y_pred = model(X_train)\n",
        "        loss = criterion(y_pred, y_train)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_losses.append(loss.item())\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_pred = model(X_val)\n",
        "            val_loss = criterion(val_pred, y_val)\n",
        "            val_losses.append(val_loss.item())\n",
        "\n",
        "    # 4. Evaluate\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        test_pred = model(X_test)\n",
        "        test_loss = criterion(test_pred, y_test).item()\n",
        "\n",
        "    print(f\"Final - Train Loss: {train_losses[-1]:.4f}, \"\n",
        "          f\"Val Loss: {val_losses[-1]:.4f}, Test Loss: {test_loss:.4f}\")\n",
        "    print(f\"Learned - weight: {model.weight.item():.4f} (true: {weight}), \"\n",
        "          f\"bias: {model.bias.item():.4f} (true: {bias})\")\n",
        "\n",
        "    # 5. Save\n",
        "    results = {\n",
        "        'model': model,\n",
        "        'train_losses': train_losses,\n",
        "        'val_losses': val_losses,\n",
        "        'test_loss': test_loss,\n",
        "        'final_weight': model.weight.item(),\n",
        "        'final_bias': model.bias.item()\n",
        "    }\n",
        "\n",
        "    if save_model:\n",
        "        os.makedirs('saved_models', exist_ok=True)\n",
        "        save_path = f'saved_models/{model_name}_lr{learning_rate}_e{epochs}.pth'\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "        print(f\"Model saved to: {save_path}\")\n",
        "        results['save_path'] = save_path\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "# TODO: Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# ============================================\n",
        "# Part 2: Running a Single Experiment\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Part 2: Running a Single Experiment\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "results = train_linear_regression(\n",
        "    learning_rate=0.01,\n",
        "    epochs=100,\n",
        "    device=device,\n",
        "    save_model=True,\n",
        "    model_name='experiment_1'\n",
        ")\n",
        "\n",
        "# TODO: Visualize results\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Training curve\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(results['train_losses'], label='Train', linewidth=2)\n",
        "plt.plot(results['val_losses'], label='Validation', linewidth=2)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss (MSE)')\n",
        "plt.legend()\n",
        "plt.title('Training Progress')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Final predictions\n",
        "plt.subplot(1, 2, 2)\n",
        "X = torch.arange(0, 1, 0.02).unsqueeze(dim=1).to(device)\n",
        "y_true = 0.7 * X + 0.3\n",
        "with torch.no_grad():\n",
        "    y_pred = results['model'](X)\n",
        "\n",
        "plt.scatter(X.cpu(), y_true.cpu(), c='b', alpha=0.6, label='True data')\n",
        "plt.plot(X.cpu(), y_pred.cpu(), 'r-', linewidth=2,\n",
        "         label=f\"Learned: y={results['final_weight']:.2f}X+{results['final_bias']:.2f}\")\n",
        "plt.plot(X.cpu(), 0.7 * X.cpu() + 0.3, 'g--', linewidth=2, label='True: y=0.7X+0.3')\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('y')\n",
        "plt.legend()\n",
        "plt.title('Final Predictions')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ============================================\n",
        "# Part 3: Hyperparameter Experiments\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Part 3: Hyperparameter Experiments\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# TODO: Experiment with different learning rates\n",
        "learning_rates = [0.001, 0.01, 0.1]\n",
        "all_results = {}\n",
        "\n",
        "for lr in learning_rates:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Experiment with learning_rate={lr}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    results = train_linear_regression(\n",
        "        learning_rate=lr,\n",
        "        epochs=100,\n",
        "        device=device\n",
        "    )\n",
        "    all_results[lr] = results\n",
        "\n",
        "# ============================================\n",
        "# Part 4: Comparing Experiments\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Part 4: Comparing Experiments\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# TODO: Compare training curves\n",
        "plt.figure(figsize=(10, 6))\n",
        "for lr, results in all_results.items():\n",
        "    plt.plot(results['train_losses'], label=f'lr={lr}', linewidth=2)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Training Loss (MSE)')\n",
        "plt.legend()\n",
        "plt.title('Training Curves: Different Learning Rates')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# TODO: Compare final results\n",
        "print(f\"\\nFinal Results Comparison:\")\n",
        "print(f\"{'LR':<10} {'Test Loss':<12} {'Weight':<10} {'Bias':<10}\")\n",
        "print(\"-\" * 45)\n",
        "for lr, results in all_results.items():\n",
        "    print(f\"{lr:<10.3f} {results['test_loss']:<12.4f} \"\n",
        "          f\"{results['final_weight']:<10.4f} {results['final_bias']:<10.4f}\")\n",
        "\n",
        "# ============================================\n",
        "# Part 5: Making Predictions with Loaded Models\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Part 5: Making Predictions with Loaded Models\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "\n",
        "# TODO: Load the best model\n",
        "class LinearRegressionModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.weight = nn.Parameter(torch.randn(1))\n",
        "        self.bias = nn.Parameter(torch.randn(1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.weight * x + self.bias\n",
        "\n",
        "\n",
        "# Load\n",
        "loaded_model = LinearRegressionModel().to(device)\n",
        "loaded_model.load_state_dict(torch.load('saved_models/experiment_1_lr0.01_e100.pth'))\n",
        "loaded_model.eval()\n",
        "\n",
        "print(\"Model loaded successfully!\")\n",
        "\n",
        "# TODO: Make predictions on new data\n",
        "new_data = torch.tensor([[0.25], [0.5], [0.75]]).to(device)\n",
        "with torch.no_grad():\n",
        "    predictions = loaded_model(new_data)\n",
        "\n",
        "print(f\"\\nPredictions for new data:\")\n",
        "for i, x in enumerate(new_data):\n",
        "    print(f\"  X={x.item():.2f} -> y={predictions[i].item():.4f}\")\n",
        "\n",
        "# ============================================\n",
        "# Part 6: Complete Summary\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Part 6: Complete Summary\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(f\"\\nWorkflow Complete!\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"Summary:\")\n",
        "print(f\"  - Trained {len(all_results)} models with different learning rates\")\n",
        "print(f\"  - Best test loss: {min(r['test_loss'] for r in all_results.values()):.4f}\")\n",
        "print(f\"  - Models saved to: saved_models/\")\n",
        "print(f\"  - Device used: {device}\")\n",
        "print(f\"\\nKey Takeaways:\")\n",
        "print(f\"  - Learning rate significantly affects convergence\")\n",
        "print(f\"  - Too small: slow learning\")\n",
        "print(f\"  - Too large: instability\")\n",
        "print(f\"  - Just right: fast, stable convergence\")\n",
        "\n",
        "# ============================================\n",
        "# Exercises\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Exercises\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Exercise 1: Epoch experiments\n",
        "print(\"\\nExercise 1: Vary number of epochs\")\n",
        "# TODO: Train with 50, 100, 200, 500 epochs\n",
        "# TODO: Compare results\n",
        "# TODO: Identify when overfitting occurs\n",
        "print(\"Tip: Look for when val loss starts increasing\")\n",
        "\n",
        "# Exercise 2: Optimizer comparison\n",
        "print(\"\\nExercise 2: Compare SGD vs Adam\")\n",
        "# TODO: Train with SGD and Adam\n",
        "# TODO: Compare convergence speed\n",
        "# TODO: Compare final results\n",
        "print(\"Tip: optim.Adam(model.parameters(), lr=0.01)\")\n",
        "\n",
        "# Exercise 3: Noise robustness\n",
        "print(\"\\nExercise 3: Add noise to data\")\n",
        "# TODO: Add Gaussian noise to training data\n",
        "# TODO: Train model on noisy data\n",
        "# TODO: Compare with clean data results\n",
        "print(\"Tip: y_noisy = y + torch.randn_like(y) * 0.1\")\n",
        "\n",
        "# Exercise 4: Different data ranges\n",
        "print(\"\\nExercise 4: Different data ranges\")\n",
        "# TODO: Try X in range [0, 2], [0, 10]\n",
        "# TODO: Try negative values\n",
        "# TODO: Analyze effect on training\n",
        "print(\"Tip: Modify torch.arange() to change range\")\n",
        "\n",
        "# Exercise 5: Complete experiments\n",
        "print(\"\\nExercise 5: Design your own experiment\")\n",
        "# TODO: Come up with a hypothesis\n",
        "# TODO: Design experiment to test it\n",
        "# TODO: Run and analyze results\n",
        "# TODO: Document findings\n",
        "print(\"Tip: What happens if you change the weight and bias?\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Exercise 5 Complete!\")\n",
        "print(\"Remember: The three mottos apply to everything!\")\n",
        "print(\"  - If in doubt, run the code!\")\n",
        "print(\"  - Experiment, experiment, experiment!\")\n",
        "print(\"  - Visualize, visualize, visualize!\")\n",
        "print(\"=\" * 60)\n"
      ]
    }
  ]
}