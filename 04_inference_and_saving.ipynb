{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMtnIs4RY4ZqpObcdrl/K1Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TranQuocHuy83/mlops_training---module02---HuyTran-/blob/main/04_inference_and_saving.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Exercise 4: Inference and Model Saving\n",
        "PyTorch Workflow Fundamentals - Module 2\n",
        "\n",
        "This exercise covers:\n",
        "- Making predictions in inference mode\n",
        "- Understanding model.eval() and torch.no_grad()\n",
        "- Saving model state\n",
        "- Loading saved models\n",
        "- Evaluating on test data\n",
        "\n",
        "Learning Mottos:\n",
        "- If in doubt, run the code!\n",
        "- Experiment, experiment, experiment!\n",
        "- Visualize, visualize, visualize!\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import datetime\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdATFM6vXC93",
        "outputId": "fc7c0adf-b124-4fd3-c390-998e71f0d3d6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x79dfd4f5ed30>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PtHvtOsZW4ue"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# ============================================\n",
        "# Part 1: Train a Model (Quick Setup)\n",
        "# ============================================\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"Part 1: Training a Model\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# TODO: Setup data\n",
        "weight = 0.7\n",
        "bias = 0.3\n",
        "X = torch.arange(0, 1, 0.02).unsqueeze(dim=1)\n",
        "y = weight * X + bias\n",
        "\n",
        "train_split = int(0.7 * len(X))\n",
        "val_split = int(0.85 * len(X))\n",
        "\n",
        "X_train, y_train = X[:train_split], y[:train_split]\n",
        "X_val, y_val = X[train_split:val_split], y[train_split:val_split]\n",
        "X_test, y_test = X[val_split:], y[val_split:]\n",
        "\n",
        "# TODO: Create and train model\n",
        "\n",
        "\n",
        "class LinearRegressionModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.weight = nn.Parameter(torch.randn(1))\n",
        "        self.bias = nn.Parameter(torch.randn(1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.weight * x + self.bias\n",
        "\n",
        "\n",
        "model = LinearRegressionModel()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "# Quick training\n",
        "epochs = 100\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    y_pred = model(X_train)\n",
        "    loss = criterion(y_pred, y_train)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "print(f\"Model trained!\")\n",
        "print(f\"Learned weight: {model.weight.item():.4f} (true: {weight})\")\n",
        "print(f\"Learned bias: {model.bias.item():.4f} (true: {bias})\")\n",
        "\n",
        "# ============================================\n",
        "# Part 2: Making Predictions in Inference Mode\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Part 2: Making Predictions\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# TODO: Set model to evaluation mode\n",
        "model.eval()\n",
        "print(\"Model set to evaluation mode\")\n",
        "\n",
        "# TODO: Make predictions on test data\n",
        "with torch.no_grad():\n",
        "    test_predictions = model(X_test)\n",
        "\n",
        "print(f\"\\nTest predictions (first 5):\")\n",
        "print(f\"  X: {X_test[:5].flatten()}\")\n",
        "print(f\"  Predicted: {test_predictions[:5].flatten()}\")\n",
        "print(f\"  Actual: {y_test[:5].flatten()}\")\n",
        "\n",
        "# TODO: Calculate test loss\n",
        "test_loss = criterion(test_predictions, y_test)\n",
        "print(f\"\\nTest Loss (MSE): {test_loss.item():.4f}\")\n",
        "\n",
        "# ============================================\n",
        "# Part 3: Visualizing Predictions\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Part 3: Visualizing Predictions\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# TODO: Plot test predictions\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(X_test, y_test, c='b', s=50, alpha=0.6, label='Actual data')\n",
        "plt.scatter(X_test, test_predictions, c='r', s=50, alpha=0.6, label='Predictions')\n",
        "plt.plot(X_test, test_predictions, 'r-', linewidth=2, alpha=0.3)\n",
        "plt.plot(X_test, weight * X_test + bias, 'g--', linewidth=2, label=f'True: y={weight}X+{bias}')\n",
        "plt.xlabel('X', fontsize=12)\n",
        "plt.ylabel('y', fontsize=12)\n",
        "plt.legend(fontsize=10)\n",
        "plt.title('Test Set: Predictions vs Actual', fontsize=14)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Predictions visualized!\")\n",
        "\n",
        "# ============================================\n",
        "# Part 4: Saving the Model\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Part 4: Saving the Model\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# TODO: Create directory if it doesn't exist\n",
        "os.makedirs('saved_models', exist_ok=True)\n",
        "\n",
        "# TODO: Save model state dict\n",
        "model_path = 'saved_models/linear_model.pth'\n",
        "torch.save(model.state_dict(), model_path)\n",
        "\n",
        "print(f\"Model saved to: {model_path}\")\n",
        "\n",
        "# TODO: Verify file was created\n",
        "if os.path.exists(model_path):\n",
        "    file_size = os.path.getsize(model_path)\n",
        "    print(f\"File size: {file_size} bytes\")\n",
        "else:\n",
        "    print(\"Error: File was not created!\")\n",
        "\n",
        "# ============================================\n",
        "# Part 5: Loading the Model\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Part 5: Loading the Model\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# TODO: Create new model instance\n",
        "loaded_model = LinearRegressionModel()\n",
        "print(\"Created new model instance\")\n",
        "print(f\"Parameters before loading:\")\n",
        "print(f\"  Weight: {loaded_model.weight.item():.4f}\")\n",
        "print(f\"  Bias: {loaded_model.bias.item():.4f}\")\n",
        "\n",
        "# TODO: Load saved state\n",
        "loaded_model.load_state_dict(torch.load(model_path))\n",
        "loaded_model.eval()\n",
        "\n",
        "print(f\"\\nParameters after loading:\")\n",
        "print(f\"  Weight: {loaded_model.weight.item():.4f}\")\n",
        "print(f\"  Bias: {loaded_model.bias.item():.4f}\")\n",
        "\n",
        "# TODO: Verify loaded model works\n",
        "with torch.no_grad():\n",
        "    loaded_predictions = loaded_model(X_test)\n",
        "    verification_loss = criterion(loaded_predictions, y_test)\n",
        "\n",
        "print(f\"\\nVerification:\")\n",
        "print(f\"  Test Loss: {verification_loss.item():.4f}\")\n",
        "print(f\"  Matches original: {torch.allclose(test_predictions, loaded_predictions)}\")\n",
        "\n",
        "# ============================================\n",
        "# Part 6: Saving Complete Checkpoints\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Part 6: Saving Complete Checkpoints\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# TODO: Create checkpoint dictionary\n",
        "checkpoint = {\n",
        "    'epoch': epochs,\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'train_loss': criterion(model(X_train), y_train).item(),\n",
        "    'val_loss': criterion(model(X_val), y_val).item(),\n",
        "    'test_loss': test_loss.item(),\n",
        "    'hyperparameters': {\n",
        "        'learning_rate': 0.01,\n",
        "        'weight': weight,\n",
        "        'bias': bias\n",
        "    },\n",
        "    'timestamp': datetime.datetime.now().isoformat(),\n",
        "    'pytorch_version': torch.__version__,\n",
        "}\n",
        "\n",
        "# TODO: Save checkpoint\n",
        "# Note: .tar is the PyTorch convention for checkpoints (contains more than just state_dict)\n",
        "checkpoint_path = 'saved_models/checkpoint.tar'\n",
        "torch.save(checkpoint, checkpoint_path)\n",
        "\n",
        "print(f\"Checkpoint saved to: {checkpoint_path}\")\n",
        "print(f\"Checkpoint contents:\")\n",
        "for key in checkpoint.keys():\n",
        "    print(f\"  {key}\")\n",
        "\n",
        "# ============================================\n",
        "# Part 7: Loading from Checkpoint\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Part 7: Loading from Checkpoint\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# TODO: Load checkpoint\n",
        "loaded_checkpoint = torch.load(checkpoint_path)\n",
        "\n",
        "print(f\"Loaded checkpoint from epoch {loaded_checkpoint['epoch']}\")\n",
        "print(f\"Train loss: {loaded_checkpoint['train_loss']:.4f}\")\n",
        "print(f\"Val loss: {loaded_checkpoint['val_loss']:.4f}\")\n",
        "print(f\"Test loss: {loaded_checkpoint['test_loss']:.4f}\")\n",
        "print(f\"Hyperparameters: {loaded_checkpoint['hyperparameters']}\")\n",
        "\n",
        "# TODO: Restore model and optimizer\n",
        "restored_model = LinearRegressionModel()\n",
        "restored_model.load_state_dict(loaded_checkpoint['model_state_dict'])\n",
        "restored_model.eval()\n",
        "\n",
        "restored_optimizer = optim.SGD(restored_model.parameters(), lr=0.01)\n",
        "restored_optimizer.load_state_dict(loaded_checkpoint['optimizer_state_dict'])\n",
        "\n",
        "print(\"\\nModel and optimizer restored successfully!\")\n",
        "\n",
        "# ============================================\n",
        "# Exercises\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Exercises\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Exercise 1: Multiple model versions\n",
        "print(\"\\nExercise 1: Save multiple model versions\")\n",
        "# TODO: Train models with different learning rates\n",
        "# TODO: Save each with a different name\n",
        "# TODO: Load and compare them\n",
        "print(\"Tip: Use f-strings for filenames: f'model_lr{lr}.pth'\")\n",
        "\n",
        "# Exercise 2: Inference on new data\n",
        "print(\"\\nExercise 2: Inference on new data\")\n",
        "# TODO: Create new data points outside training range\n",
        "# TODO: Make predictions\n",
        "# TODO: Discuss extrapolation\n",
        "print(\"Tip: Try X values like -0.5, 1.5 (outside 0-1 range)\")\n",
        "\n",
        "# Exercise 3: Model comparison\n",
        "print(\"\\nExercise 3: Model comparison\")\n",
        "# TODO: Load multiple saved models\n",
        "# TODO: Compare their predictions\n",
        "# TODO: Visualize all on same plot\n",
        "print(\"Tip: Plot multiple learned lines on one graph\")\n",
        "\n",
        "# Exercise 4: Save training history\n",
        "print(\"\\nExercise 4: Save training history\")\n",
        "# TODO: Save loss curves with checkpoint\n",
        "# TODO: Load and plot training history\n",
        "# TODO: Compare multiple training runs\n",
        "print(\"Tip: Add 'train_losses': train_losses to checkpoint\")\n",
        "\n",
        "# Exercise 5: Resume training\n",
        "print(\"\\nExercise 5: Resume training\")\n",
        "# TODO: Load checkpoint\n",
        "# TODO: Continue training from saved epoch\n",
        "# TODO: Verify it continues correctly\n",
        "print(\"Tip: Use checkpoint['epoch'] as starting point\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Exercise 4 Complete!\")\n",
        "print(\"Remember: Visualize, visualize, visualize!\")\n",
        "print(\"=\" * 60)\n"
      ]
    }
  ]
}